Spark
	+ Mac:
		https://sparkbyexamples.com/pyspark/how-to-install-pyspark-on-mac/

		$ sdk install java 11.0.23-amzn 
		$ sdk default java 11.0.23-amzn  
		
		$ python3 -m venv venv
		$ source venv/bin/activate
		$ pip install pyspark
		$ pip install pyspark[sql]
		$ pip install pyspark[pandas_on_spark]

		Exportar dependencias:
		$ pip freeze > requirements.txt

		Instalar dependencias:
		$ pip install -r requirements.txt

		Verify installation:
		$ python -c "import pyspark; print(pyspark.__version__)"

		# Create DataFrame in PySpark Shell
		data = [("Java", "20000"), ("Python", "100000"), ("Scala", "3000")]
		df = spark.createDataFrame(data)
		df.show()

		https://colab.research.google.com/drive/1G894WS7ltIUTusWWmsCnF_zQhQqZCDOc#scrollTo=hz6ALr5mMqZt
		$ wget https://jacobceles.github.io/knowledge_repo/colab_and_pyspark/cars.csv

		* loadCsv.py (Python 3.13.3, PySpark: 3.5.5):
		from pyspark.sql import SparkSession

		# Initialize Spark session
		spark = SparkSession.builder \
		 .appName("CSV Loader") \
		 .getOrCreate()

		df = spark.read.csv('cars.csv', header=True, sep=";")
		df.show(5)

		# Other csv example and resources
		https://colab.research.google.com/drive/1fa2G3YuXx3Isqyby5kFETqmWotFwtqlH?usp=sharing
		https://sparkbyexamples.com/pyspark/how-to-install-pyspark-on-mac/
		https://sparkmadeeasy.com/quick_start

# Put your code here
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("DataProcessing").getOrCreate()

data = [("1", "Jack", 22, "Data Science"),
        ("2", "Luke", 21, "Data Analytics"),
        ("3", "Leo", 24, "Micro Services")]

columns = ["ID", "Name", "Age", "Area of Interest"]
df = spark.createDataFrame(data, columns)

age_stats_df = df.describe(["Age"])
age_stats_df.write.parquet("/projects/challenge/Age")
print("Statical description of 'Age' column saved to /projects/challenge/Age")

selected_df = df.select("ID", "Name", "Age").orderBy("Name")

# Put your code here
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("DataProcessing").getOrCreate()

data = [("1", "Jack", 22, "Data Science"),
        ("2", "Luke", 21, "Data Analytics"),
        ("3", "Leo", 24, "Micro Services")]

columns = ["ID", "Name", "Age", "Area of Interest"]
df = spark.createDataFrame(data, columns)

age_stats_df = df.describe(["Age"])
age_stats_df.write.parquet("/projects/challenge/Age")
print("Statical description of 'Age' column saved to /projects/challenge/Age")

selected_df = df.select("ID", "Name", "Age").orderBy("Name", ascending=False)
selected_df.write.parquet("/projects/challenge/NameSorted")
print("DataFrame with 'ID', 'Name', and 'Age'")

spark.stop()


	* Linux:
		$ wget https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz
		$ tar -xvzf spark-3.3.2-bin-hadoop3.tgz

		$ vim ~/.bash_profile
		export SPARK_HOME=~/opt/spark-3.3.2-bin-hadoop3
		export PATH=$SPARK_HOME/bin:$PY4J_PATH:$PATH
		export PY4J_PATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.9.5-src.zip:$PY4J_PATH
		$ source ~/.bash_profile

		$ python3 -m venv .venv
		$ source .venv/bin/activate
		$ pip install pyspark==3.3.2
		$ pip install pyspark[sql]
		$ pip install pyspark[pandas_on_spark]

		Verify installation:
		$ python -c "import pyspark; print(pyspark.__version__)"


